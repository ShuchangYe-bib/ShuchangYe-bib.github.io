<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title> Shuchang Ye </title>
        <!-- Bootstrap CSS for responsive grid system -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
        <!-- Font Awesome for icons -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
        <!-- Link to the custom CSS file -->
        <link rel="stylesheet" href="./styles.css">
    </head>
    <body>
    <div class="container my-5">
        <!-- Author Overview -->
        <div class="author-overview mb-4">
            <h1> Shuchang Ye </h1>
            <p><i class="fas fa-university"></i> The University of Sydney </p>
            <p><i class="fas fa-phone"></i> +61 456639399 </p>
            <p><i class="fas fa-envelope"></i> shuchang.ye@sydney.edu.au </p>
            <h4> Research Interests </h4>
            <ul>
                <li>Multi-modal Learning</li>
                <li>Medical Image Analysis</li>
            </ul>
        </div>
        <article class="publication-item">
            <i class="publication-icon fas fa-book"></i>
            <h2> Publications </h2>
            <h3 class="publication-date"> 2019 </h3>
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">Enabling Text-free Inference in Language-guided Segmentation of Chest X-rays via Self-guidance </h5>
                    <h6 class="card-subtitle mb-2 text-muted"> Shuchang Ye, Mingyuan Meng, Mingjian Li, Dagan Feng and Jinman Kim </h6>
                    <p class="card-text"> Existing language-guided methods require clinical reports alongside the images, and hence, they are not applicable for use in image segmentation in a decision support context, but rather limited to retrospective image analysis after clinical reporting has been completed. In this study, we propose a self-guided segmentation framework (SGSeg) that leverages language guidance for training (multi-modal) while enabling text-free inference (uni-modal), which is the first that enables text-free inference in language-guided segmentation. </p>
                    <p class="card-text"><strong> Conference: </strong> the 27th international conference on medical image computing and computer assisted intervention (MICCAI 2024) </p>
                    <a href="#" class="card-link"><i class="fas fa-link"></i> Paper Link </a>
                    <a href="#" class="card-link"><i class="fas fa-globe"></i> Website </a>
                    <a href="#" class="card-link"><i class="fab fa-github"></i> GitHub </a>
                </div>
            </div>
        </article>
            <!-- Add more years and cards as needed -->
        </div>
    </div>

    <!-- Bootstrap JS and Popper.js for interactivity (optional) -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
    </body>
</html>
